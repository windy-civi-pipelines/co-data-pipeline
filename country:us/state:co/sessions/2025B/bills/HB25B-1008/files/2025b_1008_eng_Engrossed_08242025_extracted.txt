Title: LLS NO. 25B-0013.01 Christopher McMichael x4775 HOUSE BILL 25B-1008
Official Title: LLS NO. 25B-0013.01 Christopher McMichael x4775 HOUSE BILL 25B-1008
Number of Sections: 1
Source: versions - Engrossed (08/24/2025)
Media Type: application/pdf
Strikethrough Detection: 8 sections found

================================================================================

Section 1:
First Extraordinary Session
Seventy-fifth General Assembly
STATE OF COLORADO
ENGROSSED
This Version Includes All Amendments Adopted
on Second Reading in the House of Introduction
House Committees Senate Committees
Business Affairs & Labor
Appropriations
A BILL FOR AN ACT
101 CONCERNING IMPLEMENTING CONSUMER PROTECTIONS IN
102 INTERACTIONS WITH ARTIFICIAL INTELLIGENCE SYSTEMS
103 BEFORE OCTOBER 1, 2026.
Bill Summary
(Note: This summary applies to this bill as introduced and does
not reflect any amendments that may be subsequently adopted. If this bill
passes third reading in the house of introduction, a bill summary that
applies to the reengrossed version of this bill will be available at
http://leg.colorado.gov.)
The bill establishes that the use of artificial intelligence systems or
required disclosure artificial intelligence systems (artificial intelligence
systems) must comply with the "Colorado Consumer Protection Act". The
attorney general may bring a claim against a developer or a deployer that
uses an artificial intelligence system in a way that violates the "Colorado ESUOH
gnidaeR
dn2
dednemA
5202
,42
tsuguA
HOUSE SPONSORSHIP
Lindstedt and Carter,
SENATE SPONSORSHIP
Amabile and Frizell,
Shading denotes HOUSE amendment. Double underlining denotes SENATE amendment.
Capital letters or bold & italic numbers indicate new material to be added to existing law.
Dashes through the words or numbers indicate deletions from existing law.
Consumer Protection Act". A developer or a deployer of an artificial
intelligence system must disclose to a consumer when the consumer is
interacting with the artificial intelligence system and not with a human in
certain circumstances. The bill establishes certain requirements for claims
brought by the attorney general and parameters for court orders resulting
from those claims. The attorney general may adopt rules for the
implementation and enforcement of this provision of the bill.
A developer of an artificial intelligence system is also subject to
the provisions of the "Colorado Anti-discrimination Act" if the artificial
intelligence system is deployed in a way that violates the "Colorado
Anti-discrimination Act". An individual may file a complaint with the
Colorado civil rights division against the developer if the developer's
artificial intelligence system discriminates against the individual in
certain circumstances.
The bill requires that contracts entered into by a Colorado public
school, a state agency, or other public entity comply with the provisions
of the "Colorado Consumer Protection Act" or the "Colorado
Anti-discrimination Act" in relation to the use and deployment of
artificial intelligence systems and that a contractor agrees to indemnify
and hold harmless a state agency or public entity.
1 Be it enacted by the General Assembly of the State of Colorado:
2 SECTION 1. In Colorado Revised Statutes, 6-1-1702, amend (1),
3 (2) introductory portion, (3)(a), (4)(a) introductory portion, (5)
4 introductory portion, and (7) as follows:
5 6-1-1702. Developer duty to avoid algorithmic discrimination
6 - required documentation. (1) On and after February 1, 2026 OCTOBER
7 1, 2026, a developer of a high-risk artificial intelligence system shall use
8 reasonable care to protect consumers from any known or reasonably
9 foreseeable risks of algorithmic discrimination arising from the intended
10 and contracted uses of the high-risk artificial intelligence system. In any
11 enforcement action brought on or after February 1, 2026 OCTOBER 1,
12 2026, by the attorney general pursuant to section 6-1-1706, there is a
13 rebuttable presumption that a developer used reasonable care as required
14 under this section if the developer complied with this section and any
-2- 1008
1 additional requirements or obligations as set forth in rules promulgated
2 ADOPTED by the attorney general pursuant to section 6-1-1707.
3 (2) On and after February 1, 2026 OCTOBER 1, 2026, and except
4 as provided in subsection (6) of this section, a developer of a high-risk
5 artificial intelligence system shall make available to the deployer or other
6 developer of the high-risk artificial intelligence system:
7 (3) (a) Except as provided in subsection (6) of this section, a
8 developer that offers, sells, leases, licenses, gives, or otherwise makes
9 available to a deployer or other developer a high-risk artificial
10 intelligence system on or after February 1, 2026 OCTOBER 1, 2026, shall
11 make available to the deployer or other developer, to the extent feasible,
12 the documentation and information, through artifacts such as model cards,
13 dataset cards, or other impact assessments, necessary for a deployer, or
14 for a third party contracted by a deployer, to complete an impact
15 assessment pursuant to section 6-1-1703 (3).
16 (4) (a) On and after February 1, 2026 OCTOBER 1, 2026, a
17 developer shall make available, in a manner that is clear and readily
18 available on the developer's website or in a public use case inventory, a
19 statement summarizing:
20 (5) On and after February 1, 2026 OCTOBER 1, 2026, a developer
21 of a high-risk artificial intelligence system shall disclose to the attorney
22 general, in a form and manner prescribed by the attorney general, and to
23 all known deployers or other developers of the high-risk artificial
24 intelligence system, any known or reasonably foreseeable risks of
25 algorithmic discrimination arising from the intended uses of the high-risk
26 artificial intelligence system without unreasonable delay but no later than
27 ninety days after the date on which:
-3- 1008
1 (7) On and after February 1, 2026 OCTOBER 1, 2026, the attorney
2 general may require that a developer disclose to the attorney general, no
3 later than ninety days after the request and in a form and manner
4 prescribed by the attorney general, the statement or documentation
5 described in subsection (2) of this section. The attorney general may
6 evaluate such statement or documentation to ensure compliance with this
7 part 17, and the statement or documentation is not subject to disclosure
8 under the "Colorado Open Records Act", part 2 of article 72 of title 24.
9 In a disclosure pursuant to this subsection (7), a developer may designate
10 the statement or documentation as including proprietary information or
11 a trade secret. To the extent that any information contained in the
12 statement or documentation includes information subject to
13 attorney-client privilege or work-product protection, the disclosure does
14 not constitute a waiver of the privilege or protection.
15 SECTION 2. In Colorado Revised Statutes, 6-1-1703, amend (1),
16 (2)(a) introductory portion, (3)(a), (3)(c), (3)(g), (4)(a) introductory
17 portion, (4)(b) introductory portion, (5)(a) introductory portion, (7), and
18 (9) as follows:
19 6-1-1703. Deployer duty to avoid algorithmic discrimination
20 - risk management policy and program. (1) On and after February 1,
21 2026 OCTOBER 1, 2026, a deployer of a high-risk artificial intelligence
22 system shall use reasonable care to protect consumers from any known or
23 reasonably foreseeable risks of algorithmic discrimination. In any
24 enforcement action brought on or after February 1, 2026 OCTOBER 1,
25 2026, by the attorney general pursuant to section 6-1-1706, there is a
26 rebuttable presumption that a deployer of a high-risk artificial intelligence
27 system used reasonable care as required under this section if the deployer
-4- 1008
1 complied with this section and any additional requirements or obligations
2 as set forth in rules promulgated ADOPTED by the attorney general
3 pursuant to section 6-1-1707.
4 (2) (a) On and after February 1, 2026 OCTOBER 1, 2026, and
5 except as provided in subsection (6) of this section, a deployer of a
6 high-risk artificial intelligence system shall implement a risk management
7 policy and program to govern the deployer's deployment of the high-risk
8 artificial intelligence system. The risk management policy and program
9 must specify and incorporate the principles, processes, and personnel that
10 the deployer uses to identify, document, and mitigate known or
11 reasonably foreseeable risks of algorithmic discrimination. The risk
12 management policy and program must be an iterative process planned,
13 implemented, and regularly and systematically reviewed and updated over
14 the life cycle of a high-risk artificial intelligence system, requiring
15 regular, systematic review and updates. A risk management policy and
16 program implemented and maintained pursuant to this subsection (2) must
17 be reasonable considering:
18 (3) (a) Except as provided in subsections (3)(d), (3)(e), and (6) of
19 this section:
20 (I) A deployer, or a third party contracted by the deployer, that
21 deploys a high-risk artificial intelligence system on or after February 1,
22 2026 OCTOBER 1, 2026, shall complete an impact assessment for the
23 high-risk artificial intelligence system; and
24 (II) On and after February 1, 2026 OCTOBER 1, 2026, a deployer,
25 or a third party contracted by the deployer, shall complete an impact
26 assessment for a deployed high-risk artificial intelligence system at least
27 annually and within ninety days after any intentional and substantial
-5- 1008
1 modification to the high-risk artificial intelligence system is made
2 available.
3 (c) In addition to the information required under subsection (3)(b)
4 of this section, an impact assessment completed pursuant to this
5 subsection (3) following an intentional and substantial modification to a
6 high-risk artificial intelligence system on or after February 1, 2026
7 OCTOBER 1, 2026, must include a statement disclosing the extent to which
8 the high-risk artificial intelligence system was used in a manner that was
9 consistent with, or varied from, the developer's intended uses of the
10 high-risk artificial intelligence system.
11 (g) On or before February 1, 2026 OCTOBER 1, 2026, and at least
12 annually thereafter, a deployer, or a third party contracted by the deployer,
13 must review the deployment of each high-risk artificial intelligence
14 system deployed by the deployer to ensure that the high-risk artificial
15 intelligence system is not causing algorithmic discrimination.
16 (4) (a) On and after February 1, 2026 OCTOBER 1, 2026, and no
17 later than the time that a deployer deploys a high-risk artificial
18 intelligence system to make, or be a substantial factor in making, a
19 consequential decision concerning a consumer, the deployer shall:
20 (b) On and after February 1, 2026 OCTOBER 1, 2026, a deployer
21 that has deployed a high-risk artificial intelligence system to make, or be
22 a substantial factor in making, a consequential decision concerning a
23 consumer shall, if the consequential decision is adverse to the consumer,
24 provide to the consumer:
25 (5) (a) On and after February 1, 2026 OCTOBER 1, 2026, and
26 except as provided in subsection (6) of this section, a deployer shall make
27 available, in a manner that is clear and readily available on the deployer's
-6- 1008
1 website, a statement summarizing:
2 (7) If a deployer deploys a high-risk artificial intelligence system
3 on or after February 1, 2026 OCTOBER 1, 2026, and subsequently
4 discovers that the high-risk artificial intelligence system has caused
5 algorithmic discrimination, the deployer, without unreasonable delay, but
6 no later than ninety days after the date of the discovery, shall send to the
7 attorney general, in a form and manner prescribed by the attorney general,
8 a notice disclosing the discovery.
9 (9) On and after February 1, 2026 OCTOBER 1, 2026, the attorney
10 general may require that a deployer, or a third party contracted by the
11 deployer, disclose to the attorney general, no later than ninety days after
12 the request and in a form and manner prescribed by the attorney general,
13 the risk management policy implemented pursuant to subsection (2) of
14 this section, the impact assessment completed pursuant to subsection (3)
15 of this section, or the records maintained pursuant to subsection (3)(f) of
16 this section. The attorney general may evaluate the risk management
17 policy, impact assessment, or records to ensure compliance with this part
18 17, and the risk management policy, impact assessment, and records are
19 not subject to disclosure under the "Colorado Open Records Act", part 2
20 of article 72 of title 24. In a disclosure pursuant to this subsection (9), a
21 deployer may designate the statement or documentation as including
22 proprietary information or a trade secret. To the extent that any
23 information contained in the risk management policy, impact assessment,
24 or records includes information subject to attorney-client privilege or
25 work-product protection, the disclosure does not constitute a waiver of
26 the privilege or protection.
27 SECTION 3. In Colorado Revised Statutes, 6-1-1704, amend (1)
-7- 1008
1 as follows:
2 6-1-1704. Disclosure of an artificial intelligence system to
3 consumer. (1) On and after February 1, 2026 OCTOBER 1, 2026, and
4 except as provided in subsection (2) of this section, a deployer or other
5 developer that deploys, offers, sells, leases, licenses, gives, or otherwise
6 makes available an artificial intelligence system that is intended to
7 interact with consumers shall ensure the disclosure to each consumer who
8 interacts with the artificial intelligence system that the consumer is
9 interacting with an artificial intelligence system.
10 SECTION 4. Act subject to petition - effective date. This act
11 takes effect at 12:01 a.m. on the day following the expiration of the
12 ninety-day period after final adjournment of the general assembly; except
13 that, if a referendum petition is filed pursuant to section 1 (3) of article V
14 of the state constitution against this act or an item, section, or part of this
15 act within such period, then the act, item, section, or part will not take
16 effect unless approved by the people at the general election to be held in
17 November 2026 and, in such case, will take effect on the date of the
18 official declaration of the vote thereon by the governor.
-8- 1008
[DELETED: sS1 I C P I W A I S C 3O1,2 t t r v o t b w b a a]
[DELETED:  t c T a g m a r f t s i d i a w t v t " i s d a t i i t " C P A o t " A i r t t u a d oBS( i p ( ( i p (i6-1,2rf0a1eO1223r4u]
[DELETED: a (O1,2 aad(da t a d o o d a h a0iO1,2 1m2t3d4f a t p c b a d t c a i5a6( (  O a a F 1 2 O1,2  7d8a9s0(O1,2 1o2g3a k d o o d o t h a4i s a k o r f r o5a6a7n]
[DELETED: (O1,2 gl t n d a t r a i a f a mp b t a g t s o ddepuI0t1a t s T t e t a i c i t2s o d i i s t3a4n5S6( i p ( ( ( ( i7p8(960-12O1,2 2s3r f r o a d I a4eO1526r7s]
[DELETED: ca s f i r p  b t a gp(O1,2 e shpam0t d u t i d a m k o1r f r o a d T r2m3i4t l c o a h a i s r5r6p7b8(9t0(1d22O1,2 3h4(O1,2 5o6a7a d a]
[DELETED: m t t h a i s i ma(o t s a i a c p t tsh a i s o o a F 1 2O1 tc w o v f t d i u o t0h1(O1,2 2a3m r t d o e h a i4s5i6(O1,2 7l t t t t a d d a h a8i s t m o b a s f i m 9c0(O1,2 1t2a3c4p5(O1,2 6e7a]
[DELETED: w(o o a F 1 2 O1,2 a s d t t h a i s h canaa(O1,2 0g1d2t3t4t5o6t7p819n0o1d a2p i o a t s T t e t a3i4o5w6t7S]
[DELETED: a6  D o a a i s tcO1,2 edm a a a i s t i i tii w t a i s t t c ii0S1t2n3t4o5a6e7N8o]


================================================================================

Raw Text:
First Extraordinary Session
Seventy-fifth General Assembly
STATE OF COLORADO
ENGROSSED
This Version Includes All Amendments Adopted
on Second Reading in the House of Introduction
LLS NO. 25B-0013.01 Christopher McMichael x4775 HOUSE BILL 25B-1008
House Committees Senate Committees
Business Affairs & Labor
Appropriations
A BILL FOR AN ACT
101 CONCERNING IMPLEMENTING CONSUMER PROTECTIONS IN
102 INTERACTIONS WITH ARTIFICIAL INTELLIGENCE SYSTEMS
103 BEFORE OCTOBER 1, 2026.
Bill Summary
(Note: This summary applies to this bill as introduced and does
not reflect any amendments that may be subsequently adopted. If this bill
passes third reading in the house of introduction, a bill summary that
applies to the reengrossed version of this bill will be available at
http://leg.colorado.gov.)
The bill establishes that the use of artificial intelligence systems or
required disclosure artificial intelligence systems (artificial intelligence
systems) must comply with the "Colorado Consumer Protection Act". The
attorney general may bring a claim against a developer or a deployer that
uses an artificial intelligence system in a way that violates the "Colorado ESUOH
gnidaeR
dn2
dednemA
5202
,42
tsuguA
HOUSE SPONSORSHIP
Lindstedt and Carter,
SENATE SPONSORSHIP
Amabile and Frizell,
Shading denotes HOUSE amendment. Double underlining denotes SENATE amendment.
Capital letters or bold & italic numbers indicate new material to be added to existing law.
Dashes through the words or numbers indicate deletions from existing law.

Consumer Protection Act". A developer or a deployer of an artificial
intelligence system must disclose to a consumer when the consumer is
interacting with the artificial intelligence system and not with a human in
certain circumstances. The bill establishes certain requirements for claims
brought by the attorney general and parameters for court orders resulting
from those claims. The attorney general may adopt rules for the
implementation and enforcement of this provision of the bill.
A developer of an artificial intelligence system is also subject to
the provisions of the "Colorado Anti-discrimination Act" if the artificial
intelligence system is deployed in a way that violates the "Colorado
Anti-discrimination Act". An individual may file a complaint with the
Colorado civil rights division against the developer if the developer's
artificial intelligence system discriminates against the individual in
certain circumstances.
The bill requires that contracts entered into by a Colorado public
school, a state agency, or other public entity comply with the provisions
of the "Colorado Consumer Protection Act" or the "Colorado
Anti-discrimination Act" in relation to the use and deployment of
artificial intelligence systems and that a contractor agrees to indemnify
and hold harmless a state agency or public entity.
1 Be it enacted by the General Assembly of the State of Colorado:
2 SECTION 1. In Colorado Revised Statutes, 6-1-1702, amend (1),
3 (2) introductory portion, (3)(a), (4)(a) introductory portion, (5)
4 introductory portion, and (7) as follows:
5 6-1-1702. Developer duty to avoid algorithmic discrimination
6 - required documentation. (1) On and after February 1, 2026 OCTOBER
7 1, 2026, a developer of a high-risk artificial intelligence system shall use
8 reasonable care to protect consumers from any known or reasonably
9 foreseeable risks of algorithmic discrimination arising from the intended
10 and contracted uses of the high-risk artificial intelligence system. In any
11 enforcement action brought on or after February 1, 2026 OCTOBER 1,
12 2026, by the attorney general pursuant to section 6-1-1706, there is a
13 rebuttable presumption that a developer used reasonable care as required
14 under this section if the developer complied with this section and any
-2- 1008

1 additional requirements or obligations as set forth in rules promulgated
2 ADOPTED by the attorney general pursuant to section 6-1-1707.
3 (2) On and after February 1, 2026 OCTOBER 1, 2026, and except
4 as provided in subsection (6) of this section, a developer of a high-risk
5 artificial intelligence system shall make available to the deployer or other
6 developer of the high-risk artificial intelligence system:
7 (3) (a) Except as provided in subsection (6) of this section, a
8 developer that offers, sells, leases, licenses, gives, or otherwise makes
9 available to a deployer or other developer a high-risk artificial
10 intelligence system on or after February 1, 2026 OCTOBER 1, 2026, shall
11 make available to the deployer or other developer, to the extent feasible,
12 the documentation and information, through artifacts such as model cards,
13 dataset cards, or other impact assessments, necessary for a deployer, or
14 for a third party contracted by a deployer, to complete an impact
15 assessment pursuant to section 6-1-1703 (3).
16 (4) (a) On and after February 1, 2026 OCTOBER 1, 2026, a
17 developer shall make available, in a manner that is clear and readily
18 available on the developer's website or in a public use case inventory, a
19 statement summarizing:
20 (5) On and after February 1, 2026 OCTOBER 1, 2026, a developer
21 of a high-risk artificial intelligence system shall disclose to the attorney
22 general, in a form and manner prescribed by the attorney general, and to
23 all known deployers or other developers of the high-risk artificial
24 intelligence system, any known or reasonably foreseeable risks of
25 algorithmic discrimination arising from the intended uses of the high-risk
26 artificial intelligence system without unreasonable delay but no later than
27 ninety days after the date on which:
-3- 1008

1 (7) On and after February 1, 2026 OCTOBER 1, 2026, the attorney
2 general may require that a developer disclose to the attorney general, no
3 later than ninety days after the request and in a form and manner
4 prescribed by the attorney general, the statement or documentation
5 described in subsection (2) of this section. The attorney general may
6 evaluate such statement or documentation to ensure compliance with this
7 part 17, and the statement or documentation is not subject to disclosure
8 under the "Colorado Open Records Act", part 2 of article 72 of title 24.
9 In a disclosure pursuant to this subsection (7), a developer may designate
10 the statement or documentation as including proprietary information or
11 a trade secret. To the extent that any information contained in the
12 statement or documentation includes information subject to
13 attorney-client privilege or work-product protection, the disclosure does
14 not constitute a waiver of the privilege or protection.
15 SECTION 2. In Colorado Revised Statutes, 6-1-1703, amend (1),
16 (2)(a) introductory portion, (3)(a), (3)(c), (3)(g), (4)(a) introductory
17 portion, (4)(b) introductory portion, (5)(a) introductory portion, (7), and
18 (9) as follows:
19 6-1-1703. Deployer duty to avoid algorithmic discrimination
20 - risk management policy and program. (1) On and after February 1,
21 2026 OCTOBER 1, 2026, a deployer of a high-risk artificial intelligence
22 system shall use reasonable care to protect consumers from any known or
23 reasonably foreseeable risks of algorithmic discrimination. In any
24 enforcement action brought on or after February 1, 2026 OCTOBER 1,
25 2026, by the attorney general pursuant to section 6-1-1706, there is a
26 rebuttable presumption that a deployer of a high-risk artificial intelligence
27 system used reasonable care as required under this section if the deployer
-4- 1008

1 complied with this section and any additional requirements or obligations
2 as set forth in rules promulgated ADOPTED by the attorney general
3 pursuant to section 6-1-1707.
4 (2) (a) On and after February 1, 2026 OCTOBER 1, 2026, and
5 except as provided in subsection (6) of this section, a deployer of a
6 high-risk artificial intelligence system shall implement a risk management
7 policy and program to govern the deployer's deployment of the high-risk
8 artificial intelligence system. The risk management policy and program
9 must specify and incorporate the principles, processes, and personnel that
10 the deployer uses to identify, document, and mitigate known or
11 reasonably foreseeable risks of algorithmic discrimination. The risk
12 management policy and program must be an iterative process planned,
13 implemented, and regularly and systematically reviewed and updated over
14 the life cycle of a high-risk artificial intelligence system, requiring
15 regular, systematic review and updates. A risk management policy and
16 program implemented and maintained pursuant to this subsection (2) must
17 be reasonable considering:
18 (3) (a) Except as provided in subsections (3)(d), (3)(e), and (6) of
19 this section:
20 (I) A deployer, or a third party contracted by the deployer, that
21 deploys a high-risk artificial intelligence system on or after February 1,
22 2026 OCTOBER 1, 2026, shall complete an impact assessment for the
23 high-risk artificial intelligence system; and
24 (II) On and after February 1, 2026 OCTOBER 1, 2026, a deployer,
25 or a third party contracted by the deployer, shall complete an impact
26 assessment for a deployed high-risk artificial intelligence system at least
27 annually and within ninety days after any intentional and substantial
-5- 1008

1 modification to the high-risk artificial intelligence system is made
2 available.
3 (c) In addition to the information required under subsection (3)(b)
4 of this section, an impact assessment completed pursuant to this
5 subsection (3) following an intentional and substantial modification to a
6 high-risk artificial intelligence system on or after February 1, 2026
7 OCTOBER 1, 2026, must include a statement disclosing the extent to which
8 the high-risk artificial intelligence system was used in a manner that was
9 consistent with, or varied from, the developer's intended uses of the
10 high-risk artificial intelligence system.
11 (g) On or before February 1, 2026 OCTOBER 1, 2026, and at least
12 annually thereafter, a deployer, or a third party contracted by the deployer,
13 must review the deployment of each high-risk artificial intelligence
14 system deployed by the deployer to ensure that the high-risk artificial
15 intelligence system is not causing algorithmic discrimination.
16 (4) (a) On and after February 1, 2026 OCTOBER 1, 2026, and no
17 later than the time that a deployer deploys a high-risk artificial
18 intelligence system to make, or be a substantial factor in making, a
19 consequential decision concerning a consumer, the deployer shall:
20 (b) On and after February 1, 2026 OCTOBER 1, 2026, a deployer
21 that has deployed a high-risk artificial intelligence system to make, or be
22 a substantial factor in making, a consequential decision concerning a
23 consumer shall, if the consequential decision is adverse to the consumer,
24 provide to the consumer:
25 (5) (a) On and after February 1, 2026 OCTOBER 1, 2026, and
26 except as provided in subsection (6) of this section, a deployer shall make
27 available, in a manner that is clear and readily available on the deployer's
-6- 1008

1 website, a statement summarizing:
2 (7) If a deployer deploys a high-risk artificial intelligence system
3 on or after February 1, 2026 OCTOBER 1, 2026, and subsequently
4 discovers that the high-risk artificial intelligence system has caused
5 algorithmic discrimination, the deployer, without unreasonable delay, but
6 no later than ninety days after the date of the discovery, shall send to the
7 attorney general, in a form and manner prescribed by the attorney general,
8 a notice disclosing the discovery.
9 (9) On and after February 1, 2026 OCTOBER 1, 2026, the attorney
10 general may require that a deployer, or a third party contracted by the
11 deployer, disclose to the attorney general, no later than ninety days after
12 the request and in a form and manner prescribed by the attorney general,
13 the risk management policy implemented pursuant to subsection (2) of
14 this section, the impact assessment completed pursuant to subsection (3)
15 of this section, or the records maintained pursuant to subsection (3)(f) of
16 this section. The attorney general may evaluate the risk management
17 policy, impact assessment, or records to ensure compliance with this part
18 17, and the risk management policy, impact assessment, and records are
19 not subject to disclosure under the "Colorado Open Records Act", part 2
20 of article 72 of title 24. In a disclosure pursuant to this subsection (9), a
21 deployer may designate the statement or documentation as including
22 proprietary information or a trade secret. To the extent that any
23 information contained in the risk management policy, impact assessment,
24 or records includes information subject to attorney-client privilege or
25 work-product protection, the disclosure does not constitute a waiver of
26 the privilege or protection.
27 SECTION 3. In Colorado Revised Statutes, 6-1-1704, amend (1)
-7- 1008

1 as follows:
2 6-1-1704. Disclosure of an artificial intelligence system to
3 consumer. (1) On and after February 1, 2026 OCTOBER 1, 2026, and
4 except as provided in subsection (2) of this section, a deployer or other
5 developer that deploys, offers, sells, leases, licenses, gives, or otherwise
6 makes available an artificial intelligence system that is intended to
7 interact with consumers shall ensure the disclosure to each consumer who
8 interacts with the artificial intelligence system that the consumer is
9 interacting with an artificial intelligence system.
10 SECTION 4. Act subject to petition - effective date. This act
11 takes effect at 12:01 a.m. on the day following the expiration of the
12 ninety-day period after final adjournment of the general assembly; except
13 that, if a referendum petition is filed pursuant to section 1 (3) of article V
14 of the state constitution against this act or an item, section, or part of this
15 act within such period, then the act, item, section, or part will not take
16 effect unless approved by the people at the general election to be held in
17 November 2026 and, in such case, will take effect on the date of the
18 official declaration of the vote thereon by the governor.
-8- 1008

[DELETED: sS1 I C P I W A I S C 3O1,2 t t r v o t b w b a a]
[DELETED:  t c T a g m a r f t s i d i a w t v t " i s d a t i i t " C P A o t " A i r t t u a d oBS( i p ( ( i p (i6-1,2rf0a1eO1223r4u]
[DELETED: a (O1,2 aad(da t a d o o d a h a0iO1,2 1m2t3d4f a t p c b a d t c a i5a6( (  O a a F 1 2 O1,2  7d8a9s0(O1,2 1o2g3a k d o o d o t h a4i s a k o r f r o5a6a7n]
[DELETED: (O1,2 gl t n d a t r a i a f a mp b t a g t s o ddepuI0t1a t s T t e t a i c i t2s o d i i s t3a4n5S6( i p ( ( ( ( i7p8(960-12O1,2 2s3r f r o a d I a4eO1526r7s]
[DELETED: ca s f i r p  b t a gp(O1,2 e shpam0t d u t i d a m k o1r f r o a d T r2m3i4t l c o a h a i s r5r6p7b8(9t0(1d22O1,2 3h4(O1,2 5o6a7a d a]
[DELETED: m t t h a i s i ma(o t s a i a c p t tsh a i s o o a F 1 2O1 tc w o v f t d i u o t0h1(O1,2 2a3m r t d o e h a i4s5i6(O1,2 7l t t t t a d d a h a8i s t m o b a s f i m 9c0(O1,2 1t2a3c4p5(O1,2 6e7a]
[DELETED: w(o o a F 1 2 O1,2 a s d t t h a i s h canaa(O1,2 0g1d2t3t4t5o6t7p819n0o1d a2p i o a t s T t e t a3i4o5w6t7S]
[DELETED: a6  D o a a i s tcO1,2 edm a a a i s t i i tii w t a i s t t c ii0S1t2n3t4o5a6e7N8o]