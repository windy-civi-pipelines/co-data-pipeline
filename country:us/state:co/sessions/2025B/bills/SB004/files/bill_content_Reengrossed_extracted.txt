Title: Senate Bill 25B-004 Reengrossed
Official Title: 
Number of Sections: 1
Source: versions - Reengrossed
Media Type: text/html

================================================================================

Section 1:
Senate Bill 25B-004 Reengrossed Show Page and Line Numbers Senate Bill 25B-004 Reengrossed LLS NO. 25B-0017.01 Josh Schultz x5486First Extraordinary Session Seventy-fifth General Assembly State of Colorado Senate Sponsorship Rodriguez, Baisley, Ball, Coleman, Exum, Frizell, Gonzales J., Kirkmeyer, Marchman, Pelton B., Simpson, Snyder House Sponsorship Bacon, This Version Includes All Amendments Adopted in the House of IntroductionSenate Amended 3rd Reading August 25, 2025 Senate Amended 2nd Reading August 24, 2025 Senate Committees Business, Labor, & Technology Appropriations House Committees No committees scheduled. Strikethrough: removed from existing law Screen Reader Only: all text indicated as strikethrough will begin as 'deleted from existing statue' and finish with 'end deletion' All-caps or Bold and Italic: added to existing law Screen Reader Only: all text indicated as all-caps or bold and italic will begin as 'added to existing law' and finish with 'end insertion' Underline: Senate Amendment Highlight: House Amendment A Bill for an Act Page 1, Line 101Concerning measures effective no later than June 30, 2026, to Page 1, Line 102increase transparency for algorithmic systems, and, in Page 1, Line 103connection therewith, making and reducing an Page 1, Line 104appropriation. Bill Summary (Note: This summary applies to this bill as introduced and does not reflect any amendments that may be subsequently adopted. If this bill passes third reading in the house of introduction, a bill summary that applies to the reengrossed version of this bill will be available at http://leg.colorado.gov.) In 2024, the general assembly enacted Senate Bill 24-205, which created consumer protections in interactions with artificial intelligence systems (provisions). The bill eliminates these provisions and: Defines "algorithmic decision system" (system) to mean any machine-based system or computational process that uses statistical modeling, data analytics, artificial intelligence, or machine learning to generate a simplified output or is capable, for a given set of human-defined objectives, of making predictions or recommendations and is used to assist, inform, or replace human decision-making; Requires a developer of a system to, on and after February 1, 2026, provide certain disclosures to a deployer of the system; Requires a deployer of a system to, on and after February 1, 2026, provide certain disclosures to an individual who is or will be affected by a decision made, informed, or influenced by a system and provide the individual with a procedure to correct the accuracy of data that was used by the system; Provides that a developer and deployer of a system are jointly and severally liable for a violation of any law that results from the deployer's use of the developer's system; Requires a person that makes available a generative artificial intelligence system to disclose to an individual interacting with the generative artificial intelligence system that the individual is interacting with a generative artificial intelligence system; Clarifies that a violation of the bill's requirements is an unfair or deceptive trade practice under the "Colorado Consumer Protection Act"; and Permits the attorney general to adopt rules implementing the provisions of the bill. Page 2, Line 1Be it enacted by the General Assembly of the State of Colorado: Page 2, Line 2SECTIONÂ 1.Â Â In Colorado Revised Statutes, 6-1-1702, amend (1), Page 2, Line 3(2) introductory portion, (3)(a), (4)(a) introductory portion, (5) introductory portion, and (7) as follows: Page 2, Line 46-1-1702.Â Â Developer duty to avoid algorithmic discrimination Page 2, Line 5- required documentation. (1)Â Â On and after February 1, 2026 June 30, Page 2, Line 62026, a developer of a high-risk artificial intelligence system shall use Page 2, Line 7reasonable care to protect consumers from any known or reasonably Page 3, Line 1foreseeable risks of algorithmic discrimination arising from the intended Page 3, Line 2and contracted uses of the high-risk artificial intelligence system. In any Page 3, Line 3enforcement action brought on or after February 1, 2026 June 30, 2026, Page 3, Line 4by the attorney general pursuant to section 6-1-1706, there is a rebuttable Page 3, Line 5presumption that a developer used reasonable care as required under this Page 3, Line 6section if the developer complied with this section and any additional Page 3, Line 7requirements or obligations as set forth in rules promulgated adopted by the attorney general pursuant to section 6-1-1707. Page 3, Line 8(2)Â Â On and after February 1, 2026 June 30, 2026, and except as Page 3, Line 9provided in subsection (6) of this section, a developer of a high-risk Page 3, Line 10artificial intelligence system shall make available to the deployer or other developer of the high-risk artificial intelligence system: Page 3, Line 11(3)Â (a)Â Â Except as provided in subsection (6) of this section, a Page 3, Line 12developer that offers, sells, leases, licenses, gives, or otherwise makes Page 3, Line 13available to a deployer or other developer a high-risk artificial Page 3, Line 14intelligence system on or after February 1, 2026 June 30, 2026, shall Page 3, Line 15make available to the deployer or other developer, to the extent feasible, Page 3, Line 16the documentation and information, through artifacts such as model cards, Page 3, Line 17dataset cards, or other impact assessments, necessary for a deployer, or Page 3, Line 18for a third party contracted by a deployer, to complete an impact assessment pursuant to section 6-1-1703 (3). Page 3, Line 19(4)Â (a)Â Â On and after February 1, 2026 June 30, 2026, a developer Page 3, Line 20shall make available, in a manner that is clear and readily available on the Page 3, Line 21developer's website or in a public use case inventory, a statement summarizing: Page 3, Line 22(5)Â Â On and after February 1, 2026 June 30, 2026, a developer of Page 3, Line 23a high-risk artificial intelligence system shall disclose to the attorney Page 4, Line 1general, in a form and manner prescribed by the attorney general, and to Page 4, Line 2all known deployers or other developers of the high-risk artificial Page 4, Line 3intelligence system, any known or reasonably foreseeable risks of Page 4, Line 4algorithmic discrimination arising from the intended uses of the high-risk Page 4, Line 5artificial intelligence system without unreasonable delay but no later than ninety days after the date on which: Page 4, Line 6(7)Â Â On and after February 1, 2026 June 30, 2026, the attorney Page 4, Line 7general may require that a developer disclose to the attorney general, no Page 4, Line 8later than ninety days after the request and in a form and manner Page 4, Line 9prescribed by the attorney general, the statement or documentation Page 4, Line 10described in subsection (2) of this section. The attorney general may Page 4, Line 11evaluate such statement or documentation to ensure compliance with this Page 4, Line 12part 17, and the statement or documentation is not subject to disclosure Page 4, Line 13under the "Colorado Open Records Act", part 2 of article 72 of title 24. Page 4, Line 14In a disclosure made pursuant to this subsection (7), a developer may Page 4, Line 15designate the statement or documentation as including proprietary Page 4, Line 16information or a trade secret. To the extent that any information contained Page 4, Line 17in the statement or documentation includes information subject to Page 4, Line 18attorney-client privilege or work-product protection, the disclosure does not constitute a waiver of the privilege or protection. Page 4, Line 19SECTIONÂ 2.Â Â In Colorado Revised Statutes, 6-1-1703, amend (1), Page 4, Line 20(2)(a) introductory portion, (3)(a), (3)(c), (3)(g), (4)(a) introductory Page 4, Line 21portion, (4)(b) introductory portion, (5)(a) introductory portion, (7), and (9) as follows: Page 4, Line 226-1-1703.Â Â Deployer duty to avoid algorithmic discrimination Page 4, Line 23- risk management policy and program. (1)Â Â On and after February 1, Page 4, Line 242026 June 30, 2026, a deployer of a high-risk artificial intelligence Page 5, Line 1system shall use reasonable care to protect consumers from any known or Page 5, Line 2reasonably foreseeable risks of algorithmic discrimination. In any Page 5, Line 3enforcement action brought on or after February 1, 2026 June 30, 2026, Page 5, Line 4by the attorney general pursuant to section 6-1-1706, there is a rebuttable Page 5, Line 5presumption that a deployer of a high-risk artificial intelligence system Page 5, Line 6used reasonable care as required under this section if the deployer Page 5, Line 7complied with this section and any additional requirements or obligations Page 5, Line 8as set forth in rules promulgated adopted by the attorney general pursuant to section 6-1-1707. Page 5, Line 9(2)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and except Page 5, Line 10as provided in subsection (6) of this section, a deployer of a high-risk Page 5, Line 11artificial intelligence system shall implement a risk management policy Page 5, Line 12and program to govern the deployer's deployment of the high-risk Page 5, Line 13artificial intelligence system. The risk management policy and program Page 5, Line 14must specify and incorporate the principles, processes, and personnel that Page 5, Line 15the deployer uses to identify, document, and mitigate known or Page 5, Line 16reasonably foreseeable risks of algorithmic discrimination. The risk Page 5, Line 17management policy and program must be an iterative process planned, Page 5, Line 18implemented, and regularly and systematically reviewed and updated over Page 5, Line 19the life cycle of a high-risk artificial intelligence system, requiring Page 5, Line 20regular, systematic review and updates. A risk management policy and Page 5, Line 21program implemented and maintained pursuant to this subsection (2) must be reasonable considering: Page 5, Line 22(3)Â (a)Â Â Except as provided in subsections (3)(d), (3)(e), and (6) of this section: Page 5, Line 23(I)Â Â A deployer, or a third party contracted by the deployer, that Page 5, Line 24deploys a high-risk artificial intelligence system on or after February 1, Page 6, Line 12026 June 30, 2026, shall complete an impact assessment for the high-risk artificial intelligence system; and Page 6, Line 2(II)Â Â On and after February 1, 2026 June 30, 2026, a deployer, or Page 6, Line 3a third party contracted by the deployer, shall complete an impact Page 6, Line 4assessment for a deployed high-risk artificial intelligence system at least Page 6, Line 5annually and within ninety days after any intentional and substantial Page 6, Line 6modification to the high-risk artificial intelligence system is made available. Page 6, Line 7(c)Â Â In addition to the information required under subsection (3)(b) Page 6, Line 8of this section, an impact assessment completed pursuant to this Page 6, Line 9subsection (3) following an intentional and substantial modification to a Page 6, Line 10high-risk artificial intelligence system on or after February 1, 2026 June Page 6, Line 1130, 2026, must include a statement disclosing the extent to which the Page 6, Line 12high-risk artificial intelligence system was used in a manner that was Page 6, Line 13consistent with, or varied from, the developer's intended uses of the high-risk artificial intelligence system. Page 6, Line 14(g)Â Â On or before February 1, 2026 June 30, 2026, and at least Page 6, Line 15annually thereafter, a deployer, or a third party contracted by the deployer, Page 6, Line 16must review the deployment of each high-risk artificial intelligence Page 6, Line 17system deployed by the deployer to ensure that the high-risk artificial intelligence system is not causing algorithmic discrimination. Page 6, Line 18(4)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and no later Page 6, Line 19than the time that a deployer deploys a high-risk artificial intelligence Page 6, Line 20system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall: Page 6, Line 21(b)Â Â On and after February 1, 2026 June 30, 2026, a deployer that Page 6, Line 22has deployed a high-risk artificial intelligence system to make, or be a Page 7, Line 1substantial factor in making, a consequential decision concerning a Page 7, Line 2consumer shall, if the consequential decision is adverse to the consumer, provide to the consumer: Page 7, Line 3(5)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and except Page 7, Line 4as provided in subsection (6) of this section, a deployer shall make Page 7, Line 5available, in a manner that is clear and readily available on the deployer's website, a statement summarizing: Page 7, Line 6(7)Â Â If a deployer deploys a high-risk artificial intelligence system Page 7, Line 7on or after February 1, 2026 June 30, 2026, and subsequently discovers Page 7, Line 8that the high-risk artificial intelligence system has caused algorithmic Page 7, Line 9discrimination, the deployer, without unreasonable delay, but no later than Page 7, Line 10ninety days after the date of the discovery, shall send to the attorney Page 7, Line 11general, in a form and manner prescribed by the attorney general, a notice disclosing the discovery. Page 7, Line 12(9)Â Â On and after February 1, 2026 June 30, 2026, the attorney Page 7, Line 13general may require that a deployer, or a third party contracted by the Page 7, Line 14deployer, disclose to the attorney general, no later than ninety days after Page 7, Line 15the request and in a form and manner prescribed by the attorney general, Page 7, Line 16the risk management policy implemented pursuant to subsection (2) of Page 7, Line 17this section, the impact assessment completed pursuant to subsection (3) Page 7, Line 18of this section, or the records maintained pursuant to subsection (3)(f) of Page 7, Line 19this section. The attorney general may evaluate the risk management Page 7, Line 20policy, impact assessment, or records to ensure compliance with this part Page 7, Line 2117, and the risk management policy, impact assessment, and records are Page 7, Line 22not subject to disclosure under the "Colorado Open Records Act", part 2 Page 7, Line 23of article 72 of title 24. In a disclosure made pursuant to this subsection Page 7, Line 24(9), a deployer may designate the statement or documentation as including Page 8, Line 1proprietary information or a trade secret. To the extent that any Page 8, Line 2information contained in the risk management policy, impact assessment, Page 8, Line 3or records includes information subject to attorney-client privilege or Page 8, Line 4work-product protection, the disclosure does not constitute a waiver of the privilege or protection. Page 8, Line 5SECTIONÂ 3.Â Â In Colorado Revised Statutes, 6-1-1704, amend (1) as follows: Page 8, Line 66-1-1704.Â Â Disclosure of an artificial intelligence system to Page 8, Line 7consumer. (1)Â Â On and after February 1, 2026 June 30, 2026, and except Page 8, Line 8as provided in subsection (2) of this section, a deployer or other developer Page 8, Line 9that deploys, offers, sells, leases, licenses, gives, or otherwise makes Page 8, Line 10available an artificial intelligence system that is intended to interact with Page 8, Line 11consumers shall ensure the disclosure to each consumer who interacts Page 8, Line 12with the artificial intelligence system that the consumer is interacting with an artificial intelligence system. Page 8, Line 13SECTIONÂ 4.Â Â Act subject to petition - effective date. This act Page 8, Line 14takes effect at 12:01 a.m. on the day following the expiration of the Page 8, Line 15ninety-day period after final adjournment of the general assembly; except Page 8, Line 16that, if a referendum petition is filed pursuant to section 1 (3) of article V Page 8, Line 17of the state constitution against this act or an item, section, or part of this Page 8, Line 18act within such period, then the act, item, section, or part will not take Page 8, Line 19effect unless approved by the people at the general election to be held in Page 8, Line 20November 2026 and, in such case, will take effect on the date of the official declaration of the vote thereon by the governor.


================================================================================

Raw Text:
Senate Bill 25B-004 Reengrossed Show Page and Line Numbers Senate Bill 25B-004 Reengrossed LLS NO. 25B-0017.01 Josh Schultz x5486First Extraordinary Session Seventy-fifth General Assembly State of Colorado Senate Sponsorship Rodriguez, Baisley, Ball, Coleman, Exum, Frizell, Gonzales J., Kirkmeyer, Marchman, Pelton B., Simpson, Snyder House Sponsorship Bacon, This Version Includes All Amendments Adopted in the House of IntroductionSenate Amended 3rd Reading August 25, 2025 Senate Amended 2nd Reading August 24, 2025 Senate Committees Business, Labor, & Technology Appropriations House Committees No committees scheduled. Strikethrough: removed from existing law Screen Reader Only: all text indicated as strikethrough will begin as 'deleted from existing statue' and finish with 'end deletion' All-caps or Bold and Italic: added to existing law Screen Reader Only: all text indicated as all-caps or bold and italic will begin as 'added to existing law' and finish with 'end insertion' Underline: Senate Amendment Highlight: House Amendment A Bill for an Act Page 1, Line 101Concerning measures effective no later than June 30, 2026, to Page 1, Line 102increase transparency for algorithmic systems, and, in Page 1, Line 103connection therewith, making and reducing an Page 1, Line 104appropriation. Bill Summary (Note: This summary applies to this bill as introduced and does not reflect any amendments that may be subsequently adopted. If this bill passes third reading in the house of introduction, a bill summary that applies to the reengrossed version of this bill will be available at http://leg.colorado.gov.) In 2024, the general assembly enacted Senate Bill 24-205, which created consumer protections in interactions with artificial intelligence systems (provisions). The bill eliminates these provisions and: Defines "algorithmic decision system" (system) to mean any machine-based system or computational process that uses statistical modeling, data analytics, artificial intelligence, or machine learning to generate a simplified output or is capable, for a given set of human-defined objectives, of making predictions or recommendations and is used to assist, inform, or replace human decision-making; Requires a developer of a system to, on and after February 1, 2026, provide certain disclosures to a deployer of the system; Requires a deployer of a system to, on and after February 1, 2026, provide certain disclosures to an individual who is or will be affected by a decision made, informed, or influenced by a system and provide the individual with a procedure to correct the accuracy of data that was used by the system; Provides that a developer and deployer of a system are jointly and severally liable for a violation of any law that results from the deployer's use of the developer's system; Requires a person that makes available a generative artificial intelligence system to disclose to an individual interacting with the generative artificial intelligence system that the individual is interacting with a generative artificial intelligence system; Clarifies that a violation of the bill's requirements is an unfair or deceptive trade practice under the "Colorado Consumer Protection Act"; and Permits the attorney general to adopt rules implementing the provisions of the bill. Page 2, Line 1Be it enacted by the General Assembly of the State of Colorado: Page 2, Line 2SECTIONÂ 1.Â Â In Colorado Revised Statutes, 6-1-1702, amend (1), Page 2, Line 3(2) introductory portion, (3)(a), (4)(a) introductory portion, (5) introductory portion, and (7) as follows: Page 2, Line 46-1-1702.Â Â Developer duty to avoid algorithmic discrimination Page 2, Line 5- required documentation. (1)Â Â On and after February 1, 2026 June 30, Page 2, Line 62026, a developer of a high-risk artificial intelligence system shall use Page 2, Line 7reasonable care to protect consumers from any known or reasonably Page 3, Line 1foreseeable risks of algorithmic discrimination arising from the intended Page 3, Line 2and contracted uses of the high-risk artificial intelligence system. In any Page 3, Line 3enforcement action brought on or after February 1, 2026 June 30, 2026, Page 3, Line 4by the attorney general pursuant to section 6-1-1706, there is a rebuttable Page 3, Line 5presumption that a developer used reasonable care as required under this Page 3, Line 6section if the developer complied with this section and any additional Page 3, Line 7requirements or obligations as set forth in rules promulgated adopted by the attorney general pursuant to section 6-1-1707. Page 3, Line 8(2)Â Â On and after February 1, 2026 June 30, 2026, and except as Page 3, Line 9provided in subsection (6) of this section, a developer of a high-risk Page 3, Line 10artificial intelligence system shall make available to the deployer or other developer of the high-risk artificial intelligence system: Page 3, Line 11(3)Â (a)Â Â Except as provided in subsection (6) of this section, a Page 3, Line 12developer that offers, sells, leases, licenses, gives, or otherwise makes Page 3, Line 13available to a deployer or other developer a high-risk artificial Page 3, Line 14intelligence system on or after February 1, 2026 June 30, 2026, shall Page 3, Line 15make available to the deployer or other developer, to the extent feasible, Page 3, Line 16the documentation and information, through artifacts such as model cards, Page 3, Line 17dataset cards, or other impact assessments, necessary for a deployer, or Page 3, Line 18for a third party contracted by a deployer, to complete an impact assessment pursuant to section 6-1-1703 (3). Page 3, Line 19(4)Â (a)Â Â On and after February 1, 2026 June 30, 2026, a developer Page 3, Line 20shall make available, in a manner that is clear and readily available on the Page 3, Line 21developer's website or in a public use case inventory, a statement summarizing: Page 3, Line 22(5)Â Â On and after February 1, 2026 June 30, 2026, a developer of Page 3, Line 23a high-risk artificial intelligence system shall disclose to the attorney Page 4, Line 1general, in a form and manner prescribed by the attorney general, and to Page 4, Line 2all known deployers or other developers of the high-risk artificial Page 4, Line 3intelligence system, any known or reasonably foreseeable risks of Page 4, Line 4algorithmic discrimination arising from the intended uses of the high-risk Page 4, Line 5artificial intelligence system without unreasonable delay but no later than ninety days after the date on which: Page 4, Line 6(7)Â Â On and after February 1, 2026 June 30, 2026, the attorney Page 4, Line 7general may require that a developer disclose to the attorney general, no Page 4, Line 8later than ninety days after the request and in a form and manner Page 4, Line 9prescribed by the attorney general, the statement or documentation Page 4, Line 10described in subsection (2) of this section. The attorney general may Page 4, Line 11evaluate such statement or documentation to ensure compliance with this Page 4, Line 12part 17, and the statement or documentation is not subject to disclosure Page 4, Line 13under the "Colorado Open Records Act", part 2 of article 72 of title 24. Page 4, Line 14In a disclosure made pursuant to this subsection (7), a developer may Page 4, Line 15designate the statement or documentation as including proprietary Page 4, Line 16information or a trade secret. To the extent that any information contained Page 4, Line 17in the statement or documentation includes information subject to Page 4, Line 18attorney-client privilege or work-product protection, the disclosure does not constitute a waiver of the privilege or protection. Page 4, Line 19SECTIONÂ 2.Â Â In Colorado Revised Statutes, 6-1-1703, amend (1), Page 4, Line 20(2)(a) introductory portion, (3)(a), (3)(c), (3)(g), (4)(a) introductory Page 4, Line 21portion, (4)(b) introductory portion, (5)(a) introductory portion, (7), and (9) as follows: Page 4, Line 226-1-1703.Â Â Deployer duty to avoid algorithmic discrimination Page 4, Line 23- risk management policy and program. (1)Â Â On and after February 1, Page 4, Line 242026 June 30, 2026, a deployer of a high-risk artificial intelligence Page 5, Line 1system shall use reasonable care to protect consumers from any known or Page 5, Line 2reasonably foreseeable risks of algorithmic discrimination. In any Page 5, Line 3enforcement action brought on or after February 1, 2026 June 30, 2026, Page 5, Line 4by the attorney general pursuant to section 6-1-1706, there is a rebuttable Page 5, Line 5presumption that a deployer of a high-risk artificial intelligence system Page 5, Line 6used reasonable care as required under this section if the deployer Page 5, Line 7complied with this section and any additional requirements or obligations Page 5, Line 8as set forth in rules promulgated adopted by the attorney general pursuant to section 6-1-1707. Page 5, Line 9(2)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and except Page 5, Line 10as provided in subsection (6) of this section, a deployer of a high-risk Page 5, Line 11artificial intelligence system shall implement a risk management policy Page 5, Line 12and program to govern the deployer's deployment of the high-risk Page 5, Line 13artificial intelligence system. The risk management policy and program Page 5, Line 14must specify and incorporate the principles, processes, and personnel that Page 5, Line 15the deployer uses to identify, document, and mitigate known or Page 5, Line 16reasonably foreseeable risks of algorithmic discrimination. The risk Page 5, Line 17management policy and program must be an iterative process planned, Page 5, Line 18implemented, and regularly and systematically reviewed and updated over Page 5, Line 19the life cycle of a high-risk artificial intelligence system, requiring Page 5, Line 20regular, systematic review and updates. A risk management policy and Page 5, Line 21program implemented and maintained pursuant to this subsection (2) must be reasonable considering: Page 5, Line 22(3)Â (a)Â Â Except as provided in subsections (3)(d), (3)(e), and (6) of this section: Page 5, Line 23(I)Â Â A deployer, or a third party contracted by the deployer, that Page 5, Line 24deploys a high-risk artificial intelligence system on or after February 1, Page 6, Line 12026 June 30, 2026, shall complete an impact assessment for the high-risk artificial intelligence system; and Page 6, Line 2(II)Â Â On and after February 1, 2026 June 30, 2026, a deployer, or Page 6, Line 3a third party contracted by the deployer, shall complete an impact Page 6, Line 4assessment for a deployed high-risk artificial intelligence system at least Page 6, Line 5annually and within ninety days after any intentional and substantial Page 6, Line 6modification to the high-risk artificial intelligence system is made available. Page 6, Line 7(c)Â Â In addition to the information required under subsection (3)(b) Page 6, Line 8of this section, an impact assessment completed pursuant to this Page 6, Line 9subsection (3) following an intentional and substantial modification to a Page 6, Line 10high-risk artificial intelligence system on or after February 1, 2026 June Page 6, Line 1130, 2026, must include a statement disclosing the extent to which the Page 6, Line 12high-risk artificial intelligence system was used in a manner that was Page 6, Line 13consistent with, or varied from, the developer's intended uses of the high-risk artificial intelligence system. Page 6, Line 14(g)Â Â On or before February 1, 2026 June 30, 2026, and at least Page 6, Line 15annually thereafter, a deployer, or a third party contracted by the deployer, Page 6, Line 16must review the deployment of each high-risk artificial intelligence Page 6, Line 17system deployed by the deployer to ensure that the high-risk artificial intelligence system is not causing algorithmic discrimination. Page 6, Line 18(4)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and no later Page 6, Line 19than the time that a deployer deploys a high-risk artificial intelligence Page 6, Line 20system to make, or be a substantial factor in making, a consequential decision concerning a consumer, the deployer shall: Page 6, Line 21(b)Â Â On and after February 1, 2026 June 30, 2026, a deployer that Page 6, Line 22has deployed a high-risk artificial intelligence system to make, or be a Page 7, Line 1substantial factor in making, a consequential decision concerning a Page 7, Line 2consumer shall, if the consequential decision is adverse to the consumer, provide to the consumer: Page 7, Line 3(5)Â (a)Â Â On and after February 1, 2026 June 30, 2026, and except Page 7, Line 4as provided in subsection (6) of this section, a deployer shall make Page 7, Line 5available, in a manner that is clear and readily available on the deployer's website, a statement summarizing: Page 7, Line 6(7)Â Â If a deployer deploys a high-risk artificial intelligence system Page 7, Line 7on or after February 1, 2026 June 30, 2026, and subsequently discovers Page 7, Line 8that the high-risk artificial intelligence system has caused algorithmic Page 7, Line 9discrimination, the deployer, without unreasonable delay, but no later than Page 7, Line 10ninety days after the date of the discovery, shall send to the attorney Page 7, Line 11general, in a form and manner prescribed by the attorney general, a notice disclosing the discovery. Page 7, Line 12(9)Â Â On and after February 1, 2026 June 30, 2026, the attorney Page 7, Line 13general may require that a deployer, or a third party contracted by the Page 7, Line 14deployer, disclose to the attorney general, no later than ninety days after Page 7, Line 15the request and in a form and manner prescribed by the attorney general, Page 7, Line 16the risk management policy implemented pursuant to subsection (2) of Page 7, Line 17this section, the impact assessment completed pursuant to subsection (3) Page 7, Line 18of this section, or the records maintained pursuant to subsection (3)(f) of Page 7, Line 19this section. The attorney general may evaluate the risk management Page 7, Line 20policy, impact assessment, or records to ensure compliance with this part Page 7, Line 2117, and the risk management policy, impact assessment, and records are Page 7, Line 22not subject to disclosure under the "Colorado Open Records Act", part 2 Page 7, Line 23of article 72 of title 24. In a disclosure made pursuant to this subsection Page 7, Line 24(9), a deployer may designate the statement or documentation as including Page 8, Line 1proprietary information or a trade secret. To the extent that any Page 8, Line 2information contained in the risk management policy, impact assessment, Page 8, Line 3or records includes information subject to attorney-client privilege or Page 8, Line 4work-product protection, the disclosure does not constitute a waiver of the privilege or protection. Page 8, Line 5SECTIONÂ 3.Â Â In Colorado Revised Statutes, 6-1-1704, amend (1) as follows: Page 8, Line 66-1-1704.Â Â Disclosure of an artificial intelligence system to Page 8, Line 7consumer. (1)Â Â On and after February 1, 2026 June 30, 2026, and except Page 8, Line 8as provided in subsection (2) of this section, a deployer or other developer Page 8, Line 9that deploys, offers, sells, leases, licenses, gives, or otherwise makes Page 8, Line 10available an artificial intelligence system that is intended to interact with Page 8, Line 11consumers shall ensure the disclosure to each consumer who interacts Page 8, Line 12with the artificial intelligence system that the consumer is interacting with an artificial intelligence system. Page 8, Line 13SECTIONÂ 4.Â Â Act subject to petition - effective date. This act Page 8, Line 14takes effect at 12:01 a.m. on the day following the expiration of the Page 8, Line 15ninety-day period after final adjournment of the general assembly; except Page 8, Line 16that, if a referendum petition is filed pursuant to section 1 (3) of article V Page 8, Line 17of the state constitution against this act or an item, section, or part of this Page 8, Line 18act within such period, then the act, item, section, or part will not take Page 8, Line 19effect unless approved by the people at the general election to be held in Page 8, Line 20November 2026 and, in such case, will take effect on the date of the official declaration of the vote thereon by the governor.